Once in production, there’s a 3 step process to add search results in your queries at run-time:

1. Call Search API to obtain relevant context (details below)
2. Format the returned context and include as a single variable value when making requests to a Vellum Deployment
3. Pass search results to request endpoint while calling the LLM

For Step 3, make sure you have a variable in Vellum Playground where search results are entered. Details to set that up are here: [Running Searches in Playground](https://www.notion.so/Running-Searches-in-Playground-f1af082b53004a20a633d4ea454b96e0?pvs=21)

## Search API

There’s a code snippet for the Search API in the Document Index. There are 3 variables to call the API:

- `index_name` - Index that is searched across
- `query` - Search query (usually a user input)
- `options` - Optional configuration that drives search behavior. Namely used to determine the max number of results returned in the response. You can also use:

  - `weights` - to change the prioritization between keyword matches vs semantic similarity
  - `result_merging` - to automatically merge overlapping chunks into larger chunks without redundant content
  - `filters` - to perform rule-based filtering prior to matching on keywords / semantic similarity. For more info, see [Metadata Filtering](https://www.notion.so/Metadata-Filtering-6a702af7649843feafc2bb05f04cb3c8?pvs=21)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/63476604-59f8-44b4-9094-6d8f628aac5c/Untitled.png)
