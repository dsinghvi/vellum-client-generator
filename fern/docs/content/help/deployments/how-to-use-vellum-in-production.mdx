### How does Vellum help beyond the Playground?

Now that you’ve used Vellum Playground for prompt engineering and have a prompt that clears your test cases, you’re ready to start making requests against it. In production, Vellum acts as a high reliability, low latency proxy between you and the underlying model provider. This part of Vellum’s platform is called Manage.

**With just 10 lines of code** to integrate with Vellum Manage, you can:

- Track completions and measure quality in Vellum’s UI: [Tracking completions & measuring quality](https://www.notion.so/Tracking-completions-measuring-quality-d3a5f036814d48728c3e7f51995b81aa?pvs=21)
- Change prompts/model providers without making code changes & get prompt versioning: [Changing prompts in production & versioning](https://www.notion.so/Changing-prompts-in-production-versioning-58e53433a8564d008e8b353cb863173e?pvs=21)
- Perform regression tests to make sure you don’t break any existing behavior: [Backtesting with Vellum](https://www.notion.so/Backtesting-with-Vellum-56ad3a74412f4f2488556da93b6826ed?pvs=21)
- Monitor your production traffic through Vellum’s dashboards: [Monitoring production traffic](https://www.notion.so/Monitoring-production-traffic-6788f377addf4e15bb1569c70087a733?pvs=21)

Additional functionality coming soon to Vellum Manage:

- Caching requests to model providers to save costs
- A/B testing prompts in production behind the same endpoint
- Retry requests to different model providers if there is outage/downtime

### 1. Creating a deployment

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/aa8d566a-65c3-487e-9403-67ccb54cdcb6/Untitled.png)
